server:
  port: 8085

embabel:
  models:
    default-llm: gpt-4.1-mini
    llms:
      best: gpt-4.1
      balanced: gpt-4.1-mini


# Logging configuration
logging:
  level:
    org.rag4j.nomnom: INFO
    org.springframework.web: INFO
    com.embabel: INFO
    root: INFO
  pattern:
    console: "%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n"

# Application specific configuration
nomnom:
  version: 1.0.0-SNAPSHOT
  description: "NomNom Food Ordering Service for Meetings"

# Observability configuration
management:
  tracing:
    sampling:
      probability: 1 # Sample all traces for demonstration; adjust in production 1 = 100%
  zipkin:
    tracing:
      export:
        enabled: true
      endpoint: http://localhost:9411/api/v2/spans

gen_ai:
  prompt: true
  completion: true

spring:
  ai:
    chat:
      observations:
        log-prompt: true
        log-completion: true
    vectorstore:
      observations:
        log-query-response: true